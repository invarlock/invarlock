{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f119189230424f855123dd06e4ccef",
   "metadata": {},
   "source": [
    "# InvarLock: Programmatic Python API\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/invarlock/invarlock/blob/main/notebooks/invarlock_python_api.ipynb)\n",
    "\n",
    "**Purpose:** Run the InvarLock pipeline from Python code (not the CLI).\n",
    "**Runtime:** ~10 minutes\n",
    "**Requires:** `invarlock[hf]` (adapters + eval + guards + edits)\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "- Loading an HF model + tokenizer\n",
    "- Building calibration windows with a dataset provider\n",
    "- Running `CoreRunner.execute(...)`\n",
    "- Generating a certificate with `invarlock.assurance.make_certificate` (using a small report adapter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109aba7aadc941dfa6ff53b2246b5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"invarlock[hf]\"\n",
    "import sys\n",
    "import invarlock\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"InvarLock:\", invarlock.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962c9c3482448d88e69ca378be0ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!invarlock doctor --json || true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19158ea43d34abe819c1abe8b5bd9b5",
   "metadata": {},
   "source": [
    "## Build calibration windows (synthetic provider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864b99a7364461aa64506139ee03ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ.setdefault('INVARLOCK_ALLOW_NETWORK', '1')\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from invarlock.eval.data import get_provider\n",
    "\n",
    "MODEL_ID = 'sshleifer/tiny-gpt2'\n",
    "SEQ_LEN = 128\n",
    "PREVIEW_N = 16\n",
    "FINAL_N = 16\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "provider = get_provider('synthetic')\n",
    "preview, final = provider.windows(\n",
    "    tokenizer,\n",
    "    preview_n=PREVIEW_N,\n",
    "    final_n=FINAL_N,\n",
    "    seq_len=SEQ_LEN,\n",
    "    stride=SEQ_LEN,\n",
    ")\n",
    "\n",
    "calibration_data = [\n",
    "    {'input_ids': ids, 'attention_mask': mask}\n",
    "    for ids, mask in zip(\n",
    "        preview.input_ids + final.input_ids,\n",
    "        preview.attention_masks + final.attention_masks,\n",
    "        strict=False,\n",
    "    )\n",
    "]\n",
    "\n",
    "print('calibration windows:', len(calibration_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070fe37d73f3413393892019fcafa5f7",
   "metadata": {},
   "source": [
    "## Run baseline (no-op) and subject (quant_rtn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c926435bfa54e4389a3ac0c242ba3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from invarlock.adapters import HF_Causal_Auto_Adapter\n",
    "from invarlock.assurance import make_certificate, render_certificate_markdown, validate_certificate\n",
    "from invarlock.core.api import RunConfig\n",
    "from invarlock.core.runner import CoreRunner\n",
    "from invarlock.edits import NoopEdit, RTNQuantEdit\n",
    "from invarlock.guards import InvariantsGuard, SpectralGuard\n",
    "from invarlock.reporting.report_types import create_empty_report\n",
    "\n",
    "adapter = HF_Causal_Auto_Adapter()\n",
    "guards = [InvariantsGuard(), SpectralGuard()]\n",
    "\n",
    "runner = CoreRunner()\n",
    "config = RunConfig(device='auto', context={'profile': 'dev', 'tier': 'balanced'})\n",
    "\n",
    "baseline_model = adapter.load_model(MODEL_ID, device='auto')\n",
    "baseline_core = runner.execute(\n",
    "    model=baseline_model,\n",
    "    adapter=adapter,\n",
    "    edit=NoopEdit(),\n",
    "    guards=guards,\n",
    "    config=config,\n",
    "    calibration_data=calibration_data,\n",
    "    preview_n=PREVIEW_N,\n",
    "    final_n=FINAL_N,\n",
    ")\n",
    "\n",
    "subject_model = adapter.load_model(MODEL_ID, device='auto')\n",
    "subject_core = runner.execute(\n",
    "    model=subject_model,\n",
    "    adapter=adapter,\n",
    "    edit=RTNQuantEdit(bitwidth=8, per_channel=True, group_size=128, clamp_ratio=0.005),\n",
    "    guards=guards,\n",
    "    config=config,\n",
    "    calibration_data=calibration_data,\n",
    "    preview_n=PREVIEW_N,\n",
    "    final_n=FINAL_N,\n",
    ")\n",
    "\n",
    "def core_to_run_report(core, *, edit_name: str) -> dict:\n",
    "    report = create_empty_report()\n",
    "    report['meta'].update({\n",
    "        'model_id': MODEL_ID,\n",
    "        'adapter': getattr(adapter, 'name', 'auto'),\n",
    "        'device': 'auto',\n",
    "        'commit': '',\n",
    "        'seed': 42,\n",
    "        'ts': datetime.now().isoformat(),\n",
    "        'auto': None,\n",
    "    })\n",
    "    report['data'].update({\n",
    "        'dataset': 'synthetic',\n",
    "        'split': 'na',\n",
    "        'seq_len': SEQ_LEN,\n",
    "        'stride': SEQ_LEN,\n",
    "        'preview_n': PREVIEW_N,\n",
    "        'final_n': FINAL_N,\n",
    "    })\n",
    "    edit_meta = getattr(core, 'edit', {})\n",
    "    if isinstance(edit_meta, dict):\n",
    "        report['edit']['plan_digest'] = str(edit_meta.get('plan_digest', ''))\n",
    "        if isinstance(edit_meta.get('deltas'), dict):\n",
    "            report['edit']['deltas'] = edit_meta['deltas']\n",
    "    report['edit']['name'] = edit_name\n",
    "    metrics = getattr(core, 'metrics', {})\n",
    "    if isinstance(metrics, dict):\n",
    "        report['metrics'].update(metrics)\n",
    "    ew = getattr(core, 'evaluation_windows', None)\n",
    "    if isinstance(ew, dict) and ew:\n",
    "        report['evaluation_windows'] = ew\n",
    "    guards_map = getattr(core, 'guards', {})\n",
    "    if isinstance(guards_map, dict):\n",
    "        for name, result in guards_map.items():\n",
    "            if not isinstance(result, dict):\n",
    "                continue\n",
    "            report['guards'].append({\n",
    "                'name': name,\n",
    "                'policy': result.get('policy', {}),\n",
    "                'metrics': result.get('metrics', {}),\n",
    "                'actions': result.get('actions', []),\n",
    "                'violations': result.get('violations', []),\n",
    "            })\n",
    "    report['flags'].update({'guard_recovered': False, 'rollback_reason': None})\n",
    "    report['artifacts'].update({'events_path': '', 'logs_path': '', 'checkpoint_path': None})\n",
    "    return report\n",
    "\n",
    "baseline_report = core_to_run_report(baseline_core, edit_name='noop')\n",
    "subject_report = core_to_run_report(subject_core, edit_name='quant_rtn')\n",
    "\n",
    "certificate = make_certificate(subject_report, baseline_report)\n",
    "validate_certificate(certificate)\n",
    "print('overall_pass:', certificate.get('validation', {}).get('overall_pass'))\n",
    "\n",
    "Path('reports/python_api').mkdir(parents=True, exist_ok=True)\n",
    "Path('reports/python_api/evaluation.cert.json').write_text(json.dumps(certificate, indent=2), encoding='utf-8')\n",
    "\n",
    "print(render_certificate_markdown(certificate)[:800])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a23e69b61374f5ba728c522f1fa2432",
   "metadata": {},
   "source": [
    "## Verify the programmatically-generated certificate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafa7b64490543119a8fa981e4a002d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "invarlock verify --json reports/python_api/evaluation.cert.json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0929c808ce4e3d96386f6135c42215",
   "metadata": {},
   "source": [
    "## Related docs\n",
    "\n",
    "- `docs/reference/api-guide.md`\n",
    "- `docs/reference/programmatic-quickstart.md`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
