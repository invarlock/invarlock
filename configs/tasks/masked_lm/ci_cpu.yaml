# Task preset: Masked LM (encoder), CI profile, CPU-friendly

model:
  id: "<set-your-model-id>"   # e.g., bert-base-uncased
  adapter: "hf_bert"
  device: "cpu"

dataset:
  provider: "wikitext2"
  split: "validation"
  seq_len: 128
  stride: 128
  preview_n: 64
  final_n: 64
  seed: 42

eval:
  loss:
    type: "mlm"
    mask_prob: 0.15
    seed: 42
    random_token_prob: 0.10
    original_token_prob: 0.10

guards:
  order: ["invariants", "spectral", "rmt", "variance", "invariants"]
